**1,HDFS的容错机制是如何实现的**

1)多副本机制
Hdfs中的每个数据块都会划分为多个副本,并分散存储在不同的DataNode节点上.这样即时某个DataNode节点发生故障,其他节点上的副本仍然 可以保证数据的可用性和完整性.
2)快速检测和恢复
1.快速检测:HDFS使用了心跳机制,DataNode会周期性的向NameNode发送心跳信息,以保证自身的正常运行.如果nameNode长时间收不到DataNode发送的心跳信息,那么就会认为节点发生了故障,并将该节点上的所有副本标记为不可用.
2,恢复:当Hdfs发现某个节点的数据块不能用时,会尝试从其他副本所在节点找到可用的分区进行替换.
3)数据校验
Hdfs使用数据校验机制保证数据的可用性和完整性.在数据块写入时,会为该数据块计算一份校验和,并将其存储在HDFS中.当读取数据块时,HDFS会重新计算校验和并与之前存储的校验进行对比,以确保读取到的数据块的完整性和正确性.


2.介绍下MR中的数据倾斜,该如何处理?
1)


3,YARN提交作业
### 1. 客户端提交作业



- 用户在客户端准备好作业所需的代码和配置文件。
- 客户端调用 `submitApplication()` 方法向 ResourceManager（RM）提交作业。
- 客户端将作业的相关信息（如作业配置、输入数据位置、输出数据位置等）封装到一个 ApplicationSubmissionContext 对象中，并将其发送给 RM。

### 2. ResourceManager 接收作业



- RM 收到客户端提交的作业信息。
- RM 会为这个作业分配一个 ApplicationMaster（AM），并为其分配一个唯一的 Application ID。
- RM 将该作业放入调度队列中，根据调度策略决定何时启动该作业。

### 3. 启动 ApplicationMaster



- RM 找到一个合适的 NodeManager（NM），并发送请求给该 NM，要求其启动 AM。
- NM 收到请求后，会在本地启动一个 Container 来运行 AM。
- AM 启动后，会向 RM 注册，RM 会更新该作业的状态信息，表明 AM 已经成功启动。

### 4. ApplicationMaster 运行



- AM 会根据作业需求，与 RM 通信，请求资源（如 CPU、内存、容器等）。
- AM 会根据作业的类型（如 MapReduce、Spark 等）将作业拆分成多个任务，并根据任务的资源需求向 RM 申请资源。

### 5. ResourceManager 分配资源



- RM 根据集群的资源使用情况和调度策略，将可用资源分配给 AM。
- RM 会将资源信息（如分配的容器 ID、所在的 NM 等）发送给 AM。

### 6. ApplicationMaster 分配任务



- AM 收到资源信息后，将任务分配到相应的容器中。
- AM 会与相应的 NM 通信，发送任务信息和资源信息，要求其在容器中启动任务。

### 7. NodeManager 启动任务



- NM 收到 AM 的请求后，会在分配的容器中启动任务。
- NM 会为任务准备运行环境，包括加载所需的依赖、设置环境变量等。

### 8. 任务执行与监控



- 任务开始执行，AM 会对任务的执行情况进行监控。
- 任务会根据作业的逻辑（如 Map 任务、Reduce 任务等）进行数据处理操作。

### 9. 任务完成



- 任务完成后，会向 AM 发送完成信号。
- AM 会根据作业的整体进度，决定是否继续请求资源启动新的任务，或者在所有任务完成后向 RM 发送作业完成信号。

### 10. 作业完成



- 当 AM 完成所有任务后，会向 RM 发送作业完成的消息。
- RM 会清理与该作业相关的资源，并更新作业的状态信息。

### 总结



YARN 的作业提交流程涉及客户端、ResourceManager、NodeManager 和 ApplicationMaster 之间的密切协作。客户端负责提交作业，RM 负责整体资源调度和分配，NM 负责启动和管理容器及任务，AM 负责作业的具体管理和任务分配。这种架构实现了资源的高效利用和作业的分布式处理，为大规模数据处理提供了可靠的平台。



需要注意的是，不同的作业类型（如 MapReduce 或 Spark）在细节上可能会有一些差异，但总体的提交流程遵循上述基本步骤。同时，YARN 的资源调度策略和容错机制会对作业的执行产生影响，确保即使在部分节点或任务出现故障时，作业也能继续正常运行。
		